version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: cybersensei-postgres
    environment:
      POSTGRES_DB: cybersensei
      POSTGRES_USER: cybersensei
      POSTGRES_PASSWORD: cybersensei123
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - cybersensei-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cybersensei"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # CyberSensei Backend
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cybersensei-backend
    environment:
      # Database
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: cybersensei
      DB_USERNAME: cybersensei
      DB_PASSWORD: cybersensei123
      
      # Server
      SERVER_PORT: 8080
      
      # JWT
      JWT_SECRET: YourSuperSecretKeyThatShouldBeAtLeast256BitsLongForHS256AlgorithmChangeInProduction
      
      # AI Service
      AI_SERVICE_URL: http://ai:8000
      
      # Sync Agent
      CENTRAL_URL: https://central.cybersensei.io
      TENANT_ID: demo-tenant
      SYNC_ENABLED: true
      
      # Phishing
      TRACKING_URL: http://localhost:8080
      PHISHING_ENABLED: false
      
      # SMTP (configure for production)
      SMTP_HOST: smtp.gmail.com
      SMTP_PORT: 587
      SMTP_USERNAME: ""
      SMTP_PASSWORD: ""
      
      # MS Teams SSO (optional)
      TEAMS_SSO_ENABLED: false
      TEAMS_TENANT_ID: ""
      TEAMS_CLIENT_ID: ""
      TEAMS_CLIENT_SECRET: ""
      
      # Java Options
      JAVA_OPTS: "-Xms512m -Xmx1024m"
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - cybersensei-network
    volumes:
      - backend-logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # AI Service (placeholder - replace with actual AI container)
  ai:
    image: ghcr.io/ollama/ollama:latest
    container_name: cybersensei-ai
    ports:
      - "8000:11434"
    networks:
      - cybersensei-network
    volumes:
      - ai-models:/root/.ollama
    restart: unless-stopped
    # Note: This is a placeholder. Replace with your actual AI model container

networks:
  cybersensei-network:
    driver: bridge

volumes:
  postgres-data:
    driver: local
  backend-logs:
    driver: local
  ai-models:
    driver: local


