# ============================================
# PROMETHEUS ALERT RULES
# CyberSensei Central
# ============================================

groups:
  # ============================================
  # BACKEND SERVICE ALERTS
  # ============================================
  - name: backend_alerts
    interval: 30s
    rules:
      # Backend service down
      - alert: BackendDown
        expr: up{job="nestjs-backend"} == 0
        for: 1m
        labels:
          severity: critical
          service: backend
        annotations:
          summary: "CyberSensei Backend is DOWN"
          description: "The NestJS backend service has been down for more than 1 minute. Instance: {{ $labels.instance }}"

      # High API latency
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="nestjs-backend"}[5m])) > 1
        for: 5m
        labels:
          severity: warning
          service: backend
        annotations:
          summary: "High API latency detected"
          description: "95th percentile API latency is above 1 second (current: {{ $value }}s) for {{ $labels.instance }}"

      # High error rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{job="nestjs-backend",status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: backend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 5% (current: {{ $value | humanizePercentage }}) for {{ $labels.instance }}"

      # High memory usage
      - alert: HighMemoryUsage
        expr: (process_resident_memory_bytes{job="nestjs-backend"} / 1024 / 1024 / 1024) > 2
        for: 10m
        labels:
          severity: warning
          service: backend
        annotations:
          summary: "High memory usage"
          description: "Backend memory usage is above 2GB (current: {{ $value | humanize }}GB)"

      # High CPU usage
      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total{job="nestjs-backend"}[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
          service: backend
        annotations:
          summary: "High CPU usage"
          description: "Backend CPU usage is above 80% (current: {{ $value | humanizePercentage }})"

  # ============================================
  # TENANT TELEMETRY ALERTS
  # ============================================
  - name: telemetry_alerts
    interval: 1m
    rules:
      # No telemetry received from tenant in 24h
      - alert: NoTelemetryReceived
        expr: (time() - cybersensei_last_telemetry_timestamp_seconds) > 86400
        for: 5m
        labels:
          severity: critical
          service: telemetry
        annotations:
          summary: "No telemetry from tenant {{ $labels.tenant_id }}"
          description: "Tenant {{ $labels.tenant_name }} ({{ $labels.tenant_id }}) has not sent telemetry data in the last 24 hours"

      # Tenant in critical health state
      - alert: TenantCriticalHealth
        expr: cybersensei_tenant_health_status{status="critical"} == 1
        for: 10m
        labels:
          severity: critical
          service: telemetry
        annotations:
          summary: "Tenant {{ $labels.tenant_id }} in critical state"
          description: "Tenant {{ $labels.tenant_name }} ({{ $labels.tenant_id }}) has been in critical health state for more than 10 minutes"

      # High AI latency for tenant
      - alert: HighAILatency
        expr: cybersensei_tenant_ai_latency_ms > 1000
        for: 15m
        labels:
          severity: warning
          service: telemetry
        annotations:
          summary: "High AI latency for tenant {{ $labels.tenant_id }}"
          description: "Tenant {{ $labels.tenant_name }} is experiencing high AI latency (current: {{ $value }}ms)"

      # Low active users (potential issue)
      - alert: LowActiveUsers
        expr: cybersensei_tenant_active_users < 1 and cybersensei_tenant_active_users{tenant_active="true"} == 1
        for: 2h
        labels:
          severity: warning
          service: telemetry
        annotations:
          summary: "Low active users for tenant {{ $labels.tenant_id }}"
          description: "Tenant {{ $labels.tenant_name }} has had less than 1 active user for 2 hours"

  # ============================================
  # DATABASE ALERTS
  # ============================================
  - name: database_alerts
    interval: 30s
    rules:
      # PostgreSQL down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          service: database
        annotations:
          summary: "PostgreSQL is DOWN"
          description: "PostgreSQL database has been down for more than 1 minute"

      # High database connections
      - alert: HighDatabaseConnections
        expr: (pg_stat_database_numbackends / pg_settings_max_connections) > 0.8
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High database connection usage"
          description: "Database connection usage is above 80% (current: {{ $value | humanizePercentage }})"

      # Slow queries
      - alert: SlowQueries
        expr: rate(pg_stat_database_tup_returned[5m]) / rate(pg_stat_database_tup_fetched[5m]) < 0.1
        for: 10m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Slow database queries detected"
          description: "Database query efficiency is below 10% (current: {{ $value | humanizePercentage }})"

      # Database disk space
      - alert: DatabaseDiskSpaceLow
        expr: (pg_database_size_bytes / 1024 / 1024 / 1024) > 50
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Database size growing"
          description: "Database size is above 50GB (current: {{ $value | humanize }}GB)"

      # Dead tuples accumulation
      - alert: HighDeadTuples
        expr: pg_stat_user_tables_n_dead_tup > 10000
        for: 30m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High dead tuples count"
          description: "Table {{ $labels.relname }} has more than 10k dead tuples (current: {{ $value }}). Consider running VACUUM."

  # ============================================
  # SYSTEM ALERTS
  # ============================================
  - name: system_alerts
    interval: 30s
    rules:
      # High CPU usage
      - alert: HostHighCPU
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "Host CPU usage is high"
          description: "CPU usage is above 80% (current: {{ $value | humanizePercentage }}) on {{ $labels.instance }}"

      # High memory usage
      - alert: HostHighMemory
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "Host memory usage is high"
          description: "Memory usage is above 85% (current: {{ $value | humanizePercentage }}) on {{ $labels.instance }}"

      # Low disk space
      - alert: HostLowDiskSpace
        expr: (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs|squashfs|vfat"} / node_filesystem_size_bytes) * 100 < 10
        for: 5m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "Host disk space is low"
          description: "Disk space is below 10% (current: {{ $value | humanizePercentage }}) on {{ $labels.instance }} mount {{ $labels.mountpoint }}"

      # High disk I/O
      - alert: HostHighDiskIO
        expr: rate(node_disk_io_time_seconds_total[5m]) > 0.8
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High disk I/O detected"
          description: "Disk I/O time is high (current: {{ $value }}) on {{ $labels.instance }} device {{ $labels.device }}"

  # ============================================
  # LICENSE ALERTS
  # ============================================
  - name: license_alerts
    interval: 1h
    rules:
      # License expiring soon
      - alert: LicenseExpiringSoon
        expr: (cybersensei_license_expiry_timestamp_seconds - time()) < (7 * 86400)
        for: 1h
        labels:
          severity: warning
          service: license
        annotations:
          summary: "License expiring soon for tenant {{ $labels.tenant_id }}"
          description: "License for tenant {{ $labels.tenant_name }} will expire in less than 7 days"

      # License expired
      - alert: LicenseExpired
        expr: (cybersensei_license_expiry_timestamp_seconds - time()) < 0
        for: 1h
        labels:
          severity: critical
          service: license
        annotations:
          summary: "License EXPIRED for tenant {{ $labels.tenant_id }}"
          description: "License for tenant {{ $labels.tenant_name }} has EXPIRED"

  # ============================================
  # CONTAINER ALERTS
  # ============================================
  - name: container_alerts
    interval: 30s
    rules:
      # Container restart
      - alert: ContainerRestarting
        expr: rate(container_start_time_seconds[5m]) > 0
        for: 5m
        labels:
          severity: warning
          service: docker
        annotations:
          summary: "Container {{ $labels.name }} is restarting"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last 5 minutes"

      # High container CPU
      - alert: ContainerHighCPU
        expr: (rate(container_cpu_usage_seconds_total[5m]) * 100) > 80
        for: 10m
        labels:
          severity: warning
          service: docker
        annotations:
          summary: "Container {{ $labels.name }} high CPU"
          description: "Container {{ $labels.name }} CPU usage is above 80% (current: {{ $value | humanizePercentage }})"

      # High container memory
      - alert: ContainerHighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 85
        for: 10m
        labels:
          severity: warning
          service: docker
        annotations:
          summary: "Container {{ $labels.name }} high memory"
          description: "Container {{ $labels.name }} memory usage is above 85% (current: {{ $value | humanizePercentage }})"

